{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcae873c-2675-4899-b7cd-4e21bd7cd60f",
   "metadata": {},
   "source": [
    "### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc33d90-96af-4f82-b2d3-4a61164295f0",
   "metadata": {},
   "source": [
    "\tWeb scraping is the process of extracting data from websites by using automated software or scripts. It involves fetching and parsing the HTML or other structured data of web pages to extract specific information.\n",
    "    \n",
    "    The three areas it is used in:\n",
    "        1.E-commerce: Extracting product details and prices for market analysis.\n",
    "        2.Financial Research: Collecting data for investment analysis and trading strategies.\n",
    "        3.Real Estate: Gathering property information for market research and listings.\n",
    "        \n",
    "    Why it is used?:\n",
    "    \t1.Data Extraction: To extract specific information from websites.\n",
    "        2.Market Research: Gathering data for competitive analysis and market trends.\n",
    "        3.Automation: Automating the process of collecting and aggregating data from multiple sources\n",
    "        4.Sentiment Analysis: Collecting data for analyzing public opinion and sentiment on social media or review platforms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e0121b-08e2-4eb0-9695-ac71352077ce",
   "metadata": {},
   "source": [
    "### Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4523a7-7ae4-473d-825f-fe3a98547a95",
   "metadata": {},
   "source": [
    "    Manual Copy-Pasting: Manually copying and pasting information from a website.\n",
    "    Regular Expressions (Regex): Using pattern-matching to extract data from HTML or text.\n",
    "    HTML Parsing: Navigating and extracting data using libraries like BeautifulSoup.\n",
    "    XPath: Using path expressions to locate and extract data from HTML or XML documents.\n",
    "    CSS Selectors: Selecting and extracting specific HTML elements based on their attributes.\n",
    "    Web Scraping Libraries: Utilizing dedicated libraries like BeautifulSoup, Scrapy, or Selenium for automated scraping.\n",
    "    API Access: Retrieving data through structured APIs provided by websites for easier access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befe97e2-c5fb-4f57-a8f3-ce0965b1e8ed",
   "metadata": {},
   "source": [
    "### Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6da6c-46f3-4bcb-bc8c-512fe62d56f8",
   "metadata": {},
   "source": [
    "    Beautiful Soup is a Python library used for web scraping and parsing HTML or XML documents. It provides convenient methods and tools for extracting specific data from web pages by navigating through the document's structure.\n",
    "    \n",
    "    1.Simplifies HTML/XML parsing and navigation.\n",
    "    2.Easy selection of specific HTML tags and attributes.\n",
    "    3.Versatile data extraction methods.\n",
    "    4.Convenient tree traversal for nested elements.\n",
    "    5.Automatic handling of different encodings.\n",
    "    6.Seamless integration with the Requests library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15881705-e6cb-45cd-8421-a0fa01f720c4",
   "metadata": {},
   "source": [
    "### Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6e8f1-9a3b-4684-abe0-91a4b156e903",
   "metadata": {},
   "source": [
    "\tFlask is used in web scraping projects for web application development, API creation, and handling HTTP requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884fb366-dd3d-45fc-ba27-e8338bae4da4",
   "metadata": {},
   "source": [
    "### Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957b4e4-5467-4110-acc5-0d9d4ffd3fdd",
   "metadata": {},
   "source": [
    "\tAWS services used in project are Code pipeline and Elastic Bean\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
